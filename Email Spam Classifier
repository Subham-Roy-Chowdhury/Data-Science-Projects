import nltk
import os

#LOADING THE DATA
def init_lists(folder):
    a_list = []
    file_list = os.listdir(folder)
    for a_file in file_list:
         f = open(folder + a_file, 'r')
         a_list.append(f.read())
    f.close()
    return a_list

spam = init_lists('enron1/spam/')
ham = init_lists('enron1/ham/')

spam_emails = [(email, 'spam') for email in spam]
ham_emails = [(email, 'ham') for email in ham]
all_emails = spam_emails + ham_emails
print(len(all_emails))

import random 
random.shuffle(all_emails)

#PREPROCESSING THE DATA
from nltk import word_tokenize,
WordNetLemmatizer

def preprocess(sentence):
    tokens = word_tokenize(sentence)
    return [lemmatizer.lemmatize(word.lower())
for word in tokens]
    
#EXTRACTING THE FEATURES
from nltk.corpus import stopwords
stoplist = stopwords.words('english')

from collections import Counter
def get_features(text, setting):
    if setting == 'bow':
        return {word: count for word, count in Counter(preprocess(text)).items() if not word in stoplist}
    else:
        return {word: True for word in preprocess(text) if not word in stoplist}
    all_features = [(get_features(email, 'bow'),label) for(email, lablel) in all_emails]
    all_features = [(get_features(email,' '), label) for (email, label) in all_emails]

#TRAINING THE CLASSIFIER
    def train(features, samples_proportion): train_size = int(len(features) * samples_proportion)
    train_set, test_set = features[:train_size], features[train_size:]
    print('Training set size = ' + str(len(train_set)) + 'emails')
    print('Test set size = '+ str(len(test_set)) + 'emails')

from nltk import NaiveBayesClassifier, classify
classifier = NaiveBayesClassifier.train(train_set)
return train_set, test_set, classifier

train_set, test_set, classifier = train(all_features, 0.8)

#EVALUATING CLASSIFIER PERFORMANCE
def evaluate(train_set, test_set, classifier):
    print('Accuracy on the training set = ' + str(classify.accuracy(classifier, train_set)))
    print('Accuracy of the test set = ' + str(classify.accuracy(classifer, test_set)))
evaluate(train_set, test_set, classifier)

classifier.show_most_informative_features(20)






















